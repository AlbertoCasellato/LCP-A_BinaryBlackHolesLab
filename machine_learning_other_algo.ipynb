{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9440fd2-e22d-4263-9826-1622343af3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries and functions\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import pickle\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#\n",
    "#\n",
    "SAVE = lambda data, dir, name: pickle.dump(data, open(dir + name + \".pkl\", \"wb\"))   # save file\n",
    "LOAD = lambda file:            pickle.load(open(file + \".pkl\", \"rb\"))               # read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fddac177-8c26-49d8-a5b5-9fb63478a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read if file exists\n",
    "def TRY_LOAD(file):\n",
    "    try:\n",
    "        data = LOAD(file)\n",
    "        return data\n",
    "    except:\n",
    "        return 0\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a40c71-a08e-48b5-a67c-43f70727e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic paths\n",
    "ORIGIN = \"original_features\"                                         # original features\n",
    "DER_1  = \"der_features_hypothesis_1\"                                 # derived features: ver. 1\n",
    "DER_2  = \"der_features_hypothesis_2\"                                 # derived features: ver. 2\n",
    "#\n",
    "correlations_dir = \"b_correlations/\"                                 # directory of \"find_correlations\" outputs\n",
    "fitted_model_all = \"a_fitted_model/all_dataset/\"                     # directory of \"RandomForestClassifier\" outputs (using all dataset)\n",
    "fitted_model_par = \"a_fitted_model/partial_dataset/\"                 # directory of \"RandomForestClassifier\" outputs (with partial dataset)\n",
    "gini_impurities  = \"c_gini_impurities/\"                              # directory of \"Feature_Importances\" outputes (1/10 of dataset)\n",
    "#\n",
    "#\n",
    "fitted_all_original_features  = TRY_LOAD(fitted_model_all + ORIGIN)  # random forest weights (for all original dataset)\n",
    "fitted_all_der_features_hyp_1 = TRY_LOAD(fitted_model_all + DER_1)   # random forest weights (for all der. ver. 1 dataset)\n",
    "fitted_all_der_features_hyp_2 = TRY_LOAD(fitted_model_all + DER_2)   # random forest weights (for all der. ver. 2 dataset)\n",
    "#\n",
    "#\n",
    "original_features_correlation = TRY_LOAD(correlations_dir + ORIGIN)  # correlation study (for all original dataset)\n",
    "derived_features_correlation  = TRY_LOAD(correlations_dir + DER_1)   # correlation study (for all der. ver. 1 dataset)\n",
    "#\n",
    "#\n",
    "gini_impurities_of_original   = TRY_LOAD(gini_impurities + ORIGIN)   # gini impurities among original features\n",
    "#                                                                    # (average among many realizations of 1/10 of dataset)\n",
    "gini_impurities_of_derived_1  = TRY_LOAD(gini_impurities + DER_1)    # gini impurities among derived features (same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58552b3b-cb49-4182-ba89-c93c9e4e21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading original features\n",
    "def make_df(dir, file):\n",
    "    df     = pd.DataFrame()\n",
    "    df_tmp = pd.read_csv(\"data/\" + dir + \"/\" + file, delimiter = \" \", skiprows = 2)\n",
    "    #\n",
    "    df[\"ALPHA\"] = 0                                # associated with the efficiency of common envelope\n",
    "    df[\"METAL\"] = 0                                # stellar metallicity at which the black holes where produced\n",
    "    df[\"MST1\"]  = df_tmp[\"col.1:m1ZAMS/Msun\"]      # ZAMS mass of the primary member of the binary system (BS) [Msun]\n",
    "    df[\"MST2\"]  = df_tmp[\"col.2:m2ZAMS/Msun\"]      # ZAMS mass of the secondary member of the BS [Msun]\n",
    "    df[\"MBH1\"]  = df_tmp[\"col.3:m1rem/Msun\"]       # mass of the black hole (BH) from the primary member [Msun]\n",
    "    df[\"MBH2\"]  = df_tmp[\"col.4:m2rem/Msun\"]       # mass of the BH from the secondary member [Msun]\n",
    "    df[\"TIME\"]  = df_tmp[\"col.6:delay_time/Myr\"]   # time from the formation of the BS to the merger of the two BH [Myr]\n",
    "    df[\"AXIS\"]  = df_tmp[\"col.7:sma/Rsun\"]         # semi-major axis of the BS at the formation of the second-born BH [Rsun] \n",
    "    df[\"ECCE\"]  = df_tmp[\"col.8:ecc\"]              # orbital eccentricity of the BS at the formation of the second-born BH\n",
    "    df[\"ISCE\"]  = df_tmp[\"col.21:CE\"]              # True: the BS undergoes a common envelope. False: the BS goes via stable mass transfer\n",
    "    df[\"ALPHA\"] = np.float64(dir[1:])\n",
    "    df[\"METAL\"] = np.float64(file.split(\"_\")[-1].split(\".txt\")[0])\n",
    "    del df_tmp\n",
    "    return df\n",
    "    #\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6da43c7-279c-4342-a5e5-b0d028fd390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making derived features [HYPOTHESIS 1]\n",
    "def make_der_df(df):\n",
    "    df_der = pd.DataFrame()\n",
    "    df_der[\"ALPHA\"]           = df[\"ALPHA\"]\n",
    "    df_der[\"METAL\"]           = df[\"METAL\"]\n",
    "    df_der[\"MS_TOT\"]          = df[\"MST2\"] + df[\"MST1\"]                                # MST2+MST1\n",
    "    df_der[\"MS_RATIO\"]        = df[\"MST2\"] / df[\"MST1\"]                                # MST2/MST1\n",
    "    df_der[\"M_LOSS\"]          = 1 - ((df[\"MBH2\"] + df[\"MBH1\"]) / df_der[\"MS_TOT\"])     # 1-[(MBH2+MBH1)/(MST2+MST1)]\n",
    "    df_der[\"M_RATIO_LOSS\"]    = 1 - ((df[\"MBH2\"] / df[\"MBH1\"]) / df_der[\"MS_RATIO\"])   # 1-[(MBH2/MBH1)/(MST2/MST1)]\n",
    "    df_der[\"INITIAL_DENSITY\"] = df_der[\"MS_TOT\"] / (df[\"AXIS\"] ** 2)                   # (MST2+MST1)/(AXIS^2)\n",
    "    df_der[\"ISCE\"]            = df[\"ISCE\"]\n",
    "    return df_der\n",
    "    #\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d2e99c-0a63-40e8-8f78-dd0fc6ae9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_plot(columns, values, title, xlabel, ylabel):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.bar(columns, values, color = 'skyblue')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.show()\n",
    "    #\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37186a86-5434-44da-893f-325f9b2a5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading original features\n",
    "df = [make_df(dir, file) for dir in os.listdir(\"data\") for file in os.listdir(\"data/\" + dir)]\n",
    "df = pd.concat(df, ignore_index = True)\n",
    "#\n",
    "# making derived features\n",
    "df_der = make_der_df(df)\n",
    "#\n",
    "#\n",
    "# columns\n",
    "# [ORIGINAL FEATURES]\n",
    "original_columns   = [\"ALPHA\", \"METAL\", \"MST1\", \"MST2\", \"MBH1\", \"MBH2\", \"TIME\", \"AXIS\", \"ECCE\"]\n",
    "#\n",
    "# [DERIVED FEATURES - HYPOTHESIS 1]\n",
    "der_hypo_1_columns = df_der.columns[:-1]\n",
    "#\n",
    "# [DERIVED FEATURES - HYPOTHESIS 2]\n",
    "der_hypo_2_columns = [\"ALPHA\",             # as hyp 1\n",
    "                      \"METAL\",             # as hyp 1\n",
    "                      \"MS_TOT\",            # as hyp 1\n",
    "                      \"MS_RATIO\",          # as hyp 1\n",
    "                      \"MS_RATIO_INV\",      # MS_RATIO ** (-1)\n",
    "                      \"MBH_RATIO\",         # MBH2 / MBH1\n",
    "                      \"M_LOSS\",            # as hyp 1\n",
    "                      \"M_RATIO_LOSS\",      # as hyp 1\n",
    "                      \"INITIAL_DENSITY\"]   # as hyp 1\n",
    "#\n",
    "#\n",
    "# original features\n",
    "x0 = df[original_columns]\n",
    "y0 = df[\"ISCE\"]\n",
    "#\n",
    "# derived features\n",
    "x1 = df_der[der_hypo_1_columns]\n",
    "y1 = df_der[\"ISCE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3efa67a1-64c8-4b72-a4c6-1a93b4976c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALPHA</th>\n",
       "      <th>METAL</th>\n",
       "      <th>MST1</th>\n",
       "      <th>MST2</th>\n",
       "      <th>MBH1</th>\n",
       "      <th>MBH2</th>\n",
       "      <th>TIME</th>\n",
       "      <th>AXIS</th>\n",
       "      <th>ECCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>24.1323</td>\n",
       "      <td>17.1893</td>\n",
       "      <td>9.5692</td>\n",
       "      <td>5.0020</td>\n",
       "      <td>141.1783</td>\n",
       "      <td>5.1703</td>\n",
       "      <td>0.258940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>69.5474</td>\n",
       "      <td>64.3689</td>\n",
       "      <td>28.4847</td>\n",
       "      <td>39.1186</td>\n",
       "      <td>9.2023</td>\n",
       "      <td>6.4328</td>\n",
       "      <td>0.055966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>106.6977</td>\n",
       "      <td>41.0318</td>\n",
       "      <td>39.9392</td>\n",
       "      <td>38.2094</td>\n",
       "      <td>2223.2639</td>\n",
       "      <td>35.8880</td>\n",
       "      <td>0.041435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>74.3594</td>\n",
       "      <td>54.3256</td>\n",
       "      <td>30.1523</td>\n",
       "      <td>37.4020</td>\n",
       "      <td>8.7628</td>\n",
       "      <td>6.0720</td>\n",
       "      <td>0.041342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>116.6000</td>\n",
       "      <td>63.2642</td>\n",
       "      <td>41.9604</td>\n",
       "      <td>42.9817</td>\n",
       "      <td>2636.2197</td>\n",
       "      <td>40.0410</td>\n",
       "      <td>0.079504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963577</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>49.5343</td>\n",
       "      <td>41.7016</td>\n",
       "      <td>4.9807</td>\n",
       "      <td>4.6760</td>\n",
       "      <td>10772.9297</td>\n",
       "      <td>11.8280</td>\n",
       "      <td>0.251980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963578</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>89.2801</td>\n",
       "      <td>62.1861</td>\n",
       "      <td>7.3304</td>\n",
       "      <td>5.1195</td>\n",
       "      <td>16.0614</td>\n",
       "      <td>462.4200</td>\n",
       "      <td>0.999370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963579</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>36.4361</td>\n",
       "      <td>27.1551</td>\n",
       "      <td>4.0565</td>\n",
       "      <td>3.2400</td>\n",
       "      <td>2200.2712</td>\n",
       "      <td>212.1500</td>\n",
       "      <td>0.993170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963580</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>73.1220</td>\n",
       "      <td>37.7591</td>\n",
       "      <td>8.2607</td>\n",
       "      <td>4.8831</td>\n",
       "      <td>6547.9141</td>\n",
       "      <td>302.6300</td>\n",
       "      <td>0.988970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963581</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>43.1693</td>\n",
       "      <td>38.1374</td>\n",
       "      <td>7.0311</td>\n",
       "      <td>4.7031</td>\n",
       "      <td>28.6069</td>\n",
       "      <td>746.9300</td>\n",
       "      <td>0.999540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963582 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ALPHA   METAL      MST1     MST2     MBH1     MBH2        TIME  \\\n",
       "0          0.5  0.0002   24.1323  17.1893   9.5692   5.0020    141.1783   \n",
       "1          0.5  0.0002   69.5474  64.3689  28.4847  39.1186      9.2023   \n",
       "2          0.5  0.0002  106.6977  41.0318  39.9392  38.2094   2223.2639   \n",
       "3          0.5  0.0002   74.3594  54.3256  30.1523  37.4020      8.7628   \n",
       "4          0.5  0.0002  116.6000  63.2642  41.9604  42.9817   2636.2197   \n",
       "...        ...     ...       ...      ...      ...      ...         ...   \n",
       "2963577    5.0  0.0200   49.5343  41.7016   4.9807   4.6760  10772.9297   \n",
       "2963578    5.0  0.0200   89.2801  62.1861   7.3304   5.1195     16.0614   \n",
       "2963579    5.0  0.0200   36.4361  27.1551   4.0565   3.2400   2200.2712   \n",
       "2963580    5.0  0.0200   73.1220  37.7591   8.2607   4.8831   6547.9141   \n",
       "2963581    5.0  0.0200   43.1693  38.1374   7.0311   4.7031     28.6069   \n",
       "\n",
       "             AXIS      ECCE  \n",
       "0          5.1703  0.258940  \n",
       "1          6.4328  0.055966  \n",
       "2         35.8880  0.041435  \n",
       "3          6.0720  0.041342  \n",
       "4         40.0410  0.079504  \n",
       "...           ...       ...  \n",
       "2963577   11.8280  0.251980  \n",
       "2963578  462.4200  0.999370  \n",
       "2963579  212.1500  0.993170  \n",
       "2963580  302.6300  0.988970  \n",
       "2963581  746.9300  0.999540  \n",
       "\n",
       "[2963582 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67582d-d218-4fb6-ae99-51f9a0026116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bb6f1-0531-44ec-a454-8125aca220fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "902513c8-f73a-4480-ba7d-6e89f4c4b661",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d2361d-8268-40f0-9fe4-083ced7da5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import metrics\n",
    "#import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a04d0033-42fe-44cf-8221-7abdda0cd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = df.filter(['ALPHA','METAL','MST1', 'MST2', 'MBH1', 'MBH2','TIME','AXIS','ECCE'], axis=1)\n",
    "\n",
    "#target_df = df.filter(['ISCE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1e7c92-7773-40b5-bdaa-01e999681608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data_df\n",
    "#y = target_df \n",
    "\n",
    "x0, y0, x1, y1 = reading_all_datasets()\n",
    "\n",
    "X = x0\n",
    "y = y0\n",
    "# Splitting arrays or matrices into random train and test subsets\n",
    "\n",
    "# i.e. 70 % training dataset and 30 % test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf428df-2f33-4a80-ad39-448b19e45de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making_plot(X.columns, importances, \"Feature Importance Based on Recursive Feature Elimination (RFE)\", \"Features\", \"Importance\")\n",
    "\n",
    "def draw_plot(columns, values, title, xlabel, ylabel, log):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.bar(columns, values, color = 'skyblue', log=log)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a7525-0596-4c78-b61d-64038a302e42",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d69dd9-304f-435f-975a-3c97bb2e10f1",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5371c-cd86-4743-8d0d-9352c92415d7",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed3789-8384-4e8b-bc8e-aa938af91fa6",
   "metadata": {},
   "source": [
    "# Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc984be2-a80e-476e-839e-4bdf94411ff9",
   "metadata": {},
   "source": [
    "Lasso regression is a modified form of linear regression. It uses the following formula for calculation:\n",
    "\n",
    "$$\\frac{1}{2N_{training}} \\sum_{i=1}^{N_{training}} \\left( y_{real}^{(i)} -  y_{real}^{(i)} \\right)^2 + \\alpha \\sum_{j=1}^{n} a_j $$\n",
    "\n",
    "where $a_j$ is the coefficient of the j-th feature. The final term is called $l1$ penalty and $\\alpha$ is a hyperparameter that tunes the intensity of this penalty term. The higher the coefficient of a feature, the higher the value of the cost function. So, the idea of Lasso regression is to optimize the cost function reducing the absolute values of the coefficients.\n",
    "\n",
    "The $\\alpha$ hyperparameter value is found using a cross-validation approach.\n",
    "\n",
    "Trying to minimize the cost function, Lasso regression will automatically select those features that are useful, discarding the useless or redundant features. In Lasso regression, discarding a feature will make its coefficient equal to 0.\n",
    "\n",
    "So, the idea of using Lasso regression for feature selection purposeis that,e: we fit a Lasso regression on a scaled version of our dataset and we consider only those features that have a coefficient different from 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015bcd8f-211e-40e0-9568-ac5c80667218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60377bc-13f9-4fc2-96fd-40caa2707306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso_test():\n",
    "        # parameters to be tested on GridSearchCV\n",
    "        params = {\"alpha\":np.arange(0.00001, 10, 500)}\n",
    "        \n",
    "        # finding 'alpha' using k-fold cross-validation approach\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Initializing the Model\n",
    "        lasso = Lasso()\n",
    "        \n",
    "        # GridSearchCV with model, params and folds.\n",
    "        lasso_cv=GridSearchCV(lasso, param_grid=params, cv=kf)\n",
    "        lasso_cv.fit(X, y)\n",
    "        #print(\"Best Params {}\".format(lasso_cv.best_params_))\n",
    "\n",
    "        alpha = lasso_cv.best_params_['alpha']\n",
    "        \n",
    "        # calling the model with the best parameter\n",
    "        lasso1 = Lasso(alpha)\n",
    "        #lasso1 = Lasso(alpha=0.0005)\n",
    "        lasso1.fit(X_train, y_train)\n",
    "        \n",
    "        # Using np.abs() to make coefficients positive.  \n",
    "        lasso1_coef = np.abs(lasso1.coef_)\n",
    "\n",
    "        return lasso1_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1301e7-03b1-4084-8c68-20ba950ef5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the lasso method to get the feature importances\n",
    "importances_l = Lasso_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "375ae1c6-894c-46a4-a542-c18496b948ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the Column Names and Importance of Columns.\n",
    "#making_plot(X.columns, importances, \"Feature Importance Based on Lasso\", \"Features\", \"Importance\")\n",
    "draw_plot(X.columns, importances_l, \"Feature Importance Based on Lasso\", \"Features\", \"Importance\", True) #log = true\n",
    "\n",
    "#draw_plot(X.columns, importances, \"Feature Importance Based on Lasso\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3994c-74ac-4ebd-8b39-c37abc0ea4c6",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c49f8-d70d-496c-8c98-038d85c408ec",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3300a-0fef-4231-aeea-b2f8a255f0c3",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416295ff-e9e6-4fc2-a106-034fbe832ce9",
   "metadata": {},
   "source": [
    "# Permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01667eba-73d5-4dc4-a37c-5e3d3b7f20c9",
   "metadata": {},
   "source": [
    "The idea behind permutation feature importance is that, the feature importance is calculated by noticing the increase or decrease in error when we permute the values of a feature. If permuting the values causes a huge change in the error, it means the feature is important for our model. \n",
    "\n",
    "The best thing about this method is that it can be applied to every machine learning model. Its approach is model agnostic, which gives you a lot of freedom. There are no complex mathematical formulas behind it. The permutation feature importance is based on an algorithm that works as follows:\n",
    "<br> 1. Calculate the mean squared error with the original values.\n",
    "<br> 2. Shuffle the values for that features and make predictions.\n",
    "<br> 3. Calculate the mean squared error with the shuffled values.\n",
    "<br> 4. Compare the differences between them.\n",
    "<br> 5. Reverse the shuffling to get the original data back. \n",
    "<br> 6. Redo steps 2-5 using the next attribute, until the importance for every feature is determined.\n",
    "<br> 7. Sort the differences in descending order to get features with most to least importance.\n",
    "\n",
    "This technique measures the contribution of a feature by measuring the changes in the model performance after randomly shuffling its values. This approach is straightforward but can be computationally intensive for large datasets. \n",
    "\n",
    "In our code, we used a scikit-learn function where feature importance is evaluated in a predictive model by the impact on the modelâ€™s performance (here, utilizing accuracy scoring) when the values of each feature are randomly shuffled. The <i>n_repeats</i> parameter specifies the number of times each featureâ€™s values are randomly shuffled to assess its impact on the modelâ€™s performance. In our case, each feature will be permuted 30 times, and the modelâ€™s performance will be evaluated after each permutation, hence the aggregate calculation of the mean and standard deviation of the importance values. However, selecting the value of <i>n_repeats</i> has computational consequences as higher values can highlight precise and robust importance calculations but higher computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c8378d7-adec-42ea-95a2-aaa5cc04b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def permutation_test():\n",
    "    model = Ridge(alpha=1e-2).fit(X_train, y_train)\n",
    "    model.score(X_test, y_test)\n",
    "\n",
    "    r = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "    return r.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831bd06a-fb6e-439d-9ce2-b25410682b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the permutation method to get the feature importances\n",
    "importances_p = permutation_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52794b-da04-4b31-83f2-42e74b4e8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the Column Names and Importance of Columns.\n",
    "#making_plot(X.columns, importances, \"Feature Importance Based on Permutation\", \"Features\", \"Importance\")\n",
    "draw_plot(X.columns, importances_p, \"Feature Importance Based on Permutation\", \"Features\", \"Importance\", True) #log = true\n",
    "\n",
    "#draw_plot(X.columns, importances, \"Feature Importance Based on Permutation\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed7b0e-8f8e-4dad-b939-b0322a6ec28d",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be903235-6343-44d4-bca5-f9f8a15c1eb7",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ee691-e752-49aa-8e2c-16ac37cf2832",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d5e81-1d57-46ae-ad4b-b5e129d56ea9",
   "metadata": {},
   "source": [
    "# Single-Variable Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebff06-8fbe-4ab3-8da3-42c137e2ce49",
   "metadata": {},
   "source": [
    "Single-variable prediction is a method of feature importance that measures the performance of a model when only one feature is used to make predictions. \n",
    "\n",
    "This can be done by training a model using only one feature and comparing its performance to the performance of the model when all features are used. The feature that results in the highest performance when used alone is considered the most important.\n",
    "\n",
    "It should be noted that the importance of a feature may depend on the context in which it is used â€“ for example, a feature that is important in isolation may not be so important when considered in combination with other features.\n",
    "\n",
    "\n",
    "Single-variable prediction entails training an ML model for each individual feature to understand how well the variable is able to predict the target value. It consists of building a model with the individual features, evaluating across respective metrics, and observing how significant each feature is to predicting the target. It provides simplicity and intuitiveness, however, this method doesnâ€™t capture the intrinsic interactions that exist between features to create a combined impact on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d5b90-0553-46f0-98a7-bcc52b552614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "def SVP_test():\n",
    "    # Applying SelectKBest with ANOVA F-value\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    # Displaying scores for each feature\n",
    "    #feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': selector.scores_})\n",
    "    #print(feature_scores.sort_values(by='Score', ascending=False))\n",
    "    \n",
    "    return selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d7c7c-e0df-43a6-9036-cac367f01810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the Single-Variable Prediction method to get the feature importances\n",
    "importances_svp = SVP_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0a244-41b5-40ff-8ebe-c086c978cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the Column Names and Importance of Columns.\n",
    "#making_plot(X.columns, importances, \"Feature Importance Based on Single-Variable Prediction\", \"Features\", \"Importance\")\n",
    "draw_plot(X.columns, importances_svp, \"Feature Importance Based on Single-Variable Prediction\", \"Features\", \"Importance\", True) #log = true\n",
    "\n",
    "#draw_plot(X.columns, importances, \"Feature Importance Based on Single-Variable Prediction\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a2718-9c51-40ef-9e04-917ad9ffcc17",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edd32e-8e5a-4f1b-b85e-e275e26efdfd",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53842340-4d5e-4c10-8a29-2601cb5c333c",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e35a71-fb9d-4262-a454-494c8061053c",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac98941-b07f-454a-813a-9a9b0108e6da",
   "metadata": {},
   "source": [
    "RFE is a feature selection method that iteratively evaluates the importance of features and removes the least important ones until the desired number remains. It uses the modelâ€™s internal feature importance measures to guide the elimination process.\n",
    "<br> 1. Train the model on the full dataset.\n",
    "<br> 2. Rank features based on their importance scores (in our aprocach these are obtained either from the coefficients of a linear regression).\n",
    "<br> 3. Remove the least important feature(s) and retrain the model.\n",
    "<br> 4. Repeat until a stopping criterion is met, such as reaching a desired number of features or observing a performance drop.\n",
    "\n",
    "Importantly, in RFE, higher ranking values denote lower importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a263a-a11b-4092-a4d5-139aa5982fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def RFE_test():\n",
    "    # Initialize the model (LinearRegression here, but you can use others)\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Applying RFE\n",
    "    rfe = RFE(estimator=model, n_features_to_select=5)  # Change n_features_to_select as needed\n",
    "    rfe.fit(X, y)\n",
    "    \n",
    "    # Displaying ranking of features\n",
    "    #feature_ranking = pd.DataFrame({'Feature': X.columns, 'Ranking': rfe.ranking_})\n",
    "    #print(feature_ranking.sort_values(by='Ranking'))\n",
    "    \n",
    "    return rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a03b1e-f427-44c7-81f9-e09c91d4af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the permutation method to get the feature importances\n",
    "ranking_rfe = RFE_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abef462-444a-4e4b-8c29-5ff5f5ba9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ee3ea-30f5-4736-a0ff-963ee7663b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the Column Names and Importance of Columns.\n",
    "#making_plot(X.columns, importances, \"Feature Importance Based on Recursive Feature Elimination (RFE)\", \"Features\", \"Importance\")\n",
    "draw_plot(X.columns, ranking_rfe, \"Feature Ranking Based on Recursive Feature Elimination (RFE)\", \"Features\", \"Importance\", False) #log = true\n",
    "\n",
    "#draw_plot(X.columns, importances, \"Feature Importance Based on Recursive Feature Elimination (RFE)\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae033c69-cdce-4b9e-8d84-ba6cb4e93428",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258afd9-97e5-402d-b300-4572fe45c1b2",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69e5b0-6bb6-41a1-9ed6-d1548255ae96",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d5cc4-3fbb-4991-b913-85fad9511571",
   "metadata": {},
   "source": [
    "# Principal Component Analysis(PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97257b41-4fe9-455a-b4b8-325232e272f0",
   "metadata": {},
   "source": [
    "PCA is a dimensionality reduction that identifies important relationships in our data, transforms the existing data based on these relationships, and then quantifies the importance of these relationships so we can keep the most important relationships and drop the others. To remember this definition, we can break it down into four steps:\n",
    "<br>1. We identify the relationship among features through a Covariance Matrix.\n",
    "<br>2. Through the linear transformation or eigendecomposition of the Covariance Matrix, we get eigenvectors and eigenvalues.\n",
    "<br>3. Then we transform our data using Eigenvectors into principal components.\n",
    "<br>4. Lastly, we quantify the importance of these relationships using Eigenvalues and keep the important principal components.\n",
    "\n",
    "For example, below the first principal component (PC1) is mostly aligned with Time, which has the highest weight of 0.999 in absolute value. This does not imply that Time is the most imporant feature rather it means while re-calculating the dataset for PC1, Time has the largest impact. \n",
    "\n",
    "Because, Importantly, PCA is not a feature selection technique. Rather, it combines the features. Because each PC is a weighted additive combination of all the columns in the original dataset. However, the PCs are formed in such a way that the first Principal Component (PC1) explains more variance in original data compared to PC2. Likewise, PC2 explains more than PC3, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4891c84-117e-48cc-9264-09bdea1aa738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def PCA_test():\n",
    "    # Applying PCA\n",
    "    pca = PCA(n_components=2)  # Adjust n_components as needed\n",
    "    principal_components = pca.fit_transform(X)\n",
    "    \n",
    "    # Displaying explained variance ratio of each component\n",
    "    explained_variance = pd.DataFrame({'Component': range(1, pca.n_components_ + 1), 'Explained Variance': pca.explained_variance_ratio_})\n",
    "    print(explained_variance)\n",
    "\n",
    "    component_weights = pca.components_\n",
    "    #print(\"Component Weights:\\n\", component_weights)\n",
    "    \n",
    "    feature_weights_mapping = {}\n",
    "    for i, component in enumerate(component_weights):\n",
    "        component_feature_weights = zip(X.columns, component)\n",
    "        feature_weights_mapping[f\"Component {i+1}\"] = component_feature_weights\n",
    "        #sorted(component_feature_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    # Accessing feature names contributing to Component 1\n",
    "    #print(\"Feature names contributing to Component 1:\")\n",
    "    feat1 = []\n",
    "    wght1 = []\n",
    "    for feature, weight in feature_weights_mapping[\"Component 1\"]:\n",
    "        feat1.append(feature)\n",
    "        wght1.append(weight)\n",
    "        #print(f\"{feature}: {weight}\")\n",
    "    \n",
    "    # Accessing feature names contributing to Component 2\n",
    "    #print(\"Feature names contributing to Component 2:\")\n",
    "    feat2 = []\n",
    "    wght2 = []\n",
    "    for feature, weight in feature_weights_mapping[\"Component 2\"]:\n",
    "        feat2.append(feature)\n",
    "        wght2.append(weight)\n",
    "        #print(f\"{feature}: {weight}\")\n",
    "\n",
    "    return feat1, wght1, feat2, wght2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a59ce-5697-4378-922d-5a267e7ae0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the PCA method to get the features(as f1 and f2) and their corresponding importances(as weights w1 and w2)\n",
    "# along the first and second principle componants (PCA1 & PCA2)\n",
    "\n",
    "f1, w1, f2, w2 = PCA_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae974e5-8f30-4b31-a2cf-3c46b1fb77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the Column Names and Importance of Columns.\n",
    "\n",
    "#making_plot(f1, w1, \"Feature Weight Based on PCA along Component 1\", \"Features\", \"Importance\")\n",
    "#making_plot(f2, w2, \"Feature Weight Based on PCA along Component 2\", \"Features\", \"Importance\")\n",
    "\n",
    "draw_plot(f1, w1, \"Feature Weight Based on PCA along Component 1\", \"Features\", \"Importance\", True) #log = true\n",
    "\n",
    "#draw_plot(f1, w1, \"Feature Weight Based on PCA along Component 1\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ab47e-2a72-4a70-8746-f7c19feb9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(f2, w2, \"Feature Weight Based on PCA along Component 2\", \"Features\", \"Importance\", True) #log = true\n",
    "\n",
    "#draw_plot(f2, w2, \"Feature Weight Based on PCA along Component 2\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d91d7-a8dd-4265-953b-b4e4112f3bd9",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7d68e-bb42-4784-bc55-06de89e035c8",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355cb1f7-f612-4e97-80bc-1b0616e71d05",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7188b33-c0b2-4b54-9020-7064b1f6b753",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9327c8d6-2a87-4504-beed-9a81c1681616",
   "metadata": {},
   "source": [
    "A benefit of using gradient boosting is that after the boosted trees are constructed, it is relatively straightforward to retrieve importance scores for each attribute.\n",
    "\n",
    "Generally, importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions with decision trees, the higher its relative importance.\n",
    "\n",
    "This importance is calculated explicitly for each attribute in the dataset, allowing attributes to be ranked and compared to each other.\n",
    "\n",
    "Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function.\n",
    "\n",
    "The feature importances are then averaged across all of the the decision trees within the model.\n",
    "\n",
    "The comparison between the XGBoost classifier and Random Forest is that although both of these methods use tree-based learners, their architecture and algorithms are fundamentally different, which results in differences in performance and accuracy. Specifically, XGBoost uses thee 'boosting' technique whresas Random Forest uses the 'bagging' technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4514bd-a59f-4c5f-aa84-ca43c39c3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb36fd8-8162-4c40-a0e0-015f345615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgboost_test():\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    #importances = pd.DataFrame(data={\n",
    "     #   'Attribute': X_train.columns,\n",
    "      #  'Importance': model.feature_importances_\n",
    "    #})\n",
    "    return model.feature_importances_\n",
    "    #importances = importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdbe66d-6a88-441a-bafa-8b18c6818545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the permutation method to get the feature importances\n",
    "importances_xgb = xgboost_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7fe4d0-577b-404e-b0a9-3ba15f41ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the Column Names and Importance of Columns.\n",
    "#making_plot(X.columns, importances, \"Feature Importance Based on XGB Classifier\", \"Features\", \"Importance\")\n",
    "\n",
    "draw_plot(X.columns, importances_xgb, \"Feature Importance Based on XGB Classifier\", \"Features\", \"Importance\", True) #log = true\n",
    "\n",
    "#draw_plot(X.columns, importances, \"Feature Importance Based on XGB Classifier\", \"Features\", \"Importance\", False) #log = false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58037b7f-d08f-4eee-968d-d1c9e6596048",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d860-a29d-4cec-adc9-afd82b2f23cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89cf50-584b-42c2-b4fa-7aabfe420470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
